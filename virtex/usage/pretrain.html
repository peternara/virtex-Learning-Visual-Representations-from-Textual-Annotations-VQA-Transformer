
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120523111-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120523111-2');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Inconsolata&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono&display=swap" rel="stylesheet">


    <title>How to train your VirTex model? &#8212; virtex 0.9 documentation</title>

    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="How to evaluate on downstream tasks?" href="downstream.html" />
    <link rel="prev" title="VirTex Model Zoo" href="model_zoo.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="how-to-train-your-virtex-model">
<h1>How to train your VirTex model?<a class="headerlink" href="#how-to-train-your-virtex-model" title="Permalink to this headline">¶</a></h1>
<p>We provide training scripts for all type of VirTex models from the paper;
including our best-performing model and other ablations.
Our training jobs are specified by config files (YAML).
Execute all commands from project root to use the provided config files.</p>
<div class="section" id="training-the-base-virtex-model">
<h2>Training the base VirTex model<a class="headerlink" href="#training-the-base-virtex-model" title="Permalink to this headline">¶</a></h2>
<p>Train the base VirTex model with ResNet-50 visual backbone; and a textual head
with <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">=</span> <span class="pre">1,</span> <span class="pre">H</span> <span class="pre">=</span> <span class="pre">1024</span></code> using all default optimization hyperparameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">pretrain_virtex</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">config</span> <span class="n">configs</span><span class="o">/</span><span class="n">_base_bicaptioning_R_50_L1_H1024</span><span class="o">.</span><span class="n">yaml</span> \
    <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">gpus</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">machine</span> <span class="mi">8</span> \
    <span class="o">--</span><span class="n">cpu</span><span class="o">-</span><span class="n">workers</span> <span class="mi">4</span> \
    <span class="o">--</span><span class="n">serialization</span><span class="o">-</span><span class="nb">dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">VIRTEX_R_50_L1_H1024</span>
    <span class="c1"># Default: --checkpoint-every 2000 --log-every 20</span>
</pre></div>
</div>
<p>Training job will save checkpoints, tensorboard logs (loss curves and metrics),
and back up the config in <code class="docutils literal notranslate"><span class="pre">--serialization-dir</span></code>. Use <code class="docutils literal notranslate"><span class="pre">tensorboard</span> <span class="pre">--logdir</span>
<span class="pre">&lt;serialization_dir&gt;</span></code> to view training curves, validation metrics etc. directly
on tensorboard.</p>
<p>We recommend training with 8 GPUs on the same machine, although training with
multiple GPUs across machines (see: <code class="docutils literal notranslate"><span class="pre">--num-machines</span></code> and <code class="docutils literal notranslate"><span class="pre">--machine-rank</span></code>),
single GPU (<code class="docutils literal notranslate"><span class="pre">--num-gpus-per-machine</span> <span class="pre">1</span></code>) as well as CPU
(<code class="docutils literal notranslate"><span class="pre">--num-gpus-per-machine</span> <span class="pre">0</span></code>) is also supported. Using multiple GPUs for
interactive debugging with PDB is not supported, as PDB and <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code>
module do not play nice.</p>
</div>
<hr class="docutils" />
<div class="section" id="reproducing-all-virtex-ablations">
<h2>Reproducing all VirTex ablations<a class="headerlink" href="#reproducing-all-virtex-ablations" title="Permalink to this headline">¶</a></h2>
<p>To reproduce all ablations from the <a class="reference external" href="https://arxiv.org/abs/2006.06666">paper</a>,
replace the <code class="docutils literal notranslate"><span class="pre">--config</span></code> argument in above command with the following (all
assumed to be relative to project root):</p>
<div class="section" id="pretraining-task-ablations">
<h3>Pretraining Task Ablations<a class="headerlink" href="#pretraining-task-ablations" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Bicaptioning:</strong> configs/task_ablations/bicaptioning_R_50_L1_H2048.yaml</p></li>
<li><p><strong>Forward Captioning:</strong> configs/task_ablations/captioning_R_50_L1_H2048.yaml</p></li>
<li><p><strong>Token Classification:</strong> configs/task_ablations/token_classification_R_50.yaml</p></li>
<li><p><strong>Multilabel Classification:</strong> configs/task_ablations/multilabel_classification_R_50.yaml</p></li>
<li><p><strong>Masked Language Modeling:</strong> configs/task_ablations/masked_lm_R_50_L1_H2048.yaml</p></li>
</ol>
</div>
<div class="section" id="transformer-size-ablations">
<h3>Transformer Size Ablations<a class="headerlink" href="#transformer-size-ablations" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Width (H = 512):</strong> configs/width_ablations/bicaptioning_R_50_L1_H512.yaml</p></li>
<li><p><strong>Width (H = 768):</strong> configs/width_ablations/bicaptioning_R_50_L1_H768.yaml</p></li>
<li><p><strong>Width (H = 1024):</strong> configs/width_ablations/bicaptioning_R_50_L1_H1024.yaml</p></li>
<li><p><strong>Width (H = 2048):</strong> configs/width_ablations/bicaptioning_R_50_L1_H2048.yaml</p></li>
<li><p><strong>Depth (L = 1):</strong> configs/depth_ablations/bicaptioning_R_50_L1_H1024.yaml</p></li>
<li><p><strong>Depth (L = 2):</strong> configs/depth_ablations/bicaptioning_R_50_L2_H1024.yaml</p></li>
<li><p><strong>Depth (L = 3):</strong> configs/depth_ablations/bicaptioning_R_50_L3_H1024.yaml</p></li>
<li><p><strong>Depth (L = 4):</strong> configs/depth_ablations/bicaptioning_R_50_L4_H1024.yaml</p></li>
</ol>
</div>
<div class="section" id="backbone-ablations">
<h3>Backbone Ablations<a class="headerlink" href="#backbone-ablations" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>ResNet-50:</strong> configs/backbone_ablations/bicaptioning_R_50_L1_H1024.yaml</p></li>
<li><p><strong>ResNet-50 w2x:</strong> configs/backbone_ablations/bicaptioning_R_50W2X_L1_H1024.yaml</p></li>
<li><p><strong>ResNet-101:</strong> configs/backbone_ablations/bicaptioning_R_101_L1_H1024.yaml</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Pretraining Task Ablations</strong> (1), <strong>Transformer Size Ablations</strong> (3 and 5)
and <strong>Backbone Ablations</strong> (1) are all the same exact model.</p>
</div>
</div>
<div class="section" id="data-efficiency-experiments">
<h3>Data Efficiency Experiments<a class="headerlink" href="#data-efficiency-experiments" title="Permalink to this headline">¶</a></h3>
<p>These are VirTex models trained on a subset of COCO Captions dataset. For example,
train a base VirTex model on randomly selected <code class="docutils literal notranslate"><span class="pre">50%</span></code> of COCO Captions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">pretrain_virtex</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">config</span> <span class="n">configs</span><span class="o">/</span><span class="n">_base_bicaptioning_R_50_L1_H1024</span><span class="o">.</span><span class="n">yaml</span> \
    <span class="o">--</span><span class="n">config</span><span class="o">-</span><span class="n">override</span> <span class="n">DATA</span><span class="o">.</span><span class="n">USE_PERCENTAGE</span> <span class="mf">50.0</span> \
    <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">gpus</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">machine</span> <span class="mi">8</span> \
    <span class="o">--</span><span class="n">cpu</span><span class="o">-</span><span class="n">workers</span> <span class="mi">4</span> \
    <span class="o">--</span><span class="n">serialization</span><span class="o">-</span><span class="nb">dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">VIRTEX_R_50_L1_H1024_PERCENT_50</span>
    <span class="c1"># Default: --checkpoint-every 2000 --log-every 20</span>
</pre></div>
</div>
<p>COCO Captions provides five captions per image. To train with one fixed caption
per image, add <code class="docutils literal notranslate"><span class="pre">DATA.USE_SINGLE_CAPTION</span> <span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">--config-override</span></code>.</p>
<p>The randomly selected subset is deterministic across runs based on random seed
(<code class="docutils literal notranslate"><span class="pre">RANDOM_SEED</span></code> in config). When training on less than <code class="docutils literal notranslate"><span class="pre">50%</span></code> dataset size, we
recommend using multiple random seeds (results will have a variance of <code class="docutils literal notranslate"><span class="pre">±1%</span></code>).</p>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">virtex</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup_dependencies.html">How to setup this codebase?</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">VirTex Model Zoo</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to train your VirTex model?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-the-base-virtex-model">Training the base VirTex model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reproducing-all-virtex-ablations">Reproducing all VirTex ablations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="downstream.html">How to evaluate on downstream tasks?</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../config.html">virtex.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factories.html">virtex.factories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">virtex.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">virtex.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">virtex.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optim.html">virtex.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">virtex.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">virtex.model_zoo</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="model_zoo.html" title="previous chapter">VirTex Model Zoo</a></li>
      <li>Next: <a href="downstream.html" title="next chapter">How to evaluate on downstream tasks?</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Karan Desai and Justin Johnson.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.1.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/virtex/usage/pretrain.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>