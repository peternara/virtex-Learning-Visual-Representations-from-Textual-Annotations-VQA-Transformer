
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120523111-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120523111-2');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Inconsolata&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono&display=swap" rel="stylesheet">


    <title>How to evaluate on downstream tasks? &#8212; virtex 0.9 documentation</title>

    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="virtex.config" href="../config.html" />
    <link rel="prev" title="How to train your VirTex model?" href="pretrain.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="how-to-evaluate-on-downstream-tasks">
<h1>How to evaluate on downstream tasks?<a class="headerlink" href="#how-to-evaluate-on-downstream-tasks" title="Permalink to this headline">¶</a></h1>
<p>In our paper, we evaluate our pretrained VirTex models on seven different
downstream tasks. Our codebase supports all of these evaluations. Throughout
this documentation, we consider a specific example of our VirTex pretrained
model being evaluated for ensuring filepath uniformity in the following example
command snippets. Paths can be trivially adjusted for any other VirTex model;
evaluating the baselines (MoCo, ImageNet-supervised, Random Init) require
additional changes in commands, explained in the last sub-section.</p>
<p>As an example, consider a pretraining job for our best performing VirTex model
(<code class="docutils literal notranslate"><span class="pre">width_ablations/bicaptioning_R_50_L1_H2048.yaml</span></code>). The serialization
directory might look something like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>/tmp/bicaptioning_R_50_L1_H2048
    pretrain_config.yaml
    log-rank0.txt    # stdout/stderr per GPU process
    log-rank1.txt
    ...
    log-rank7.txt
    checkpoint_2000.pth
    checkpoint_4000.pth
    ...
    checkpoint_498000.pth
    checkpoint_500000.pth    # serialized checkpoints
    train_captioning_forward/
        events.out.* ...    # tensorboard logs
    ...
</pre></div>
</div>
<p>We evaluate all checkpoints on <strong>PASCAL VOC 2007 Linear Classification</strong>, and
then evaluate the best checkpoint (here, it was iteration 500000) on all other
downstream tasks.</p>
<div class="section" id="pascal-voc-2007-linear-classification">
<h2>PASCAL VOC 2007 Linear Classification<a class="headerlink" href="#pascal-voc-2007-linear-classification" title="Permalink to this headline">¶</a></h2>
<p>Evaluate a single VirTex pretrained checkpoint on VOC 2007 <code class="docutils literal notranslate"><span class="pre">trainval</span></code> split:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/clf_voc07.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --down-config configs/downstream/voc07_clf.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">1</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048
</pre></div>
</div>
<p>To evaluate recent 100 checkpoints in the sub-directory, this command can be
looped over as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="o">((</span><span class="nv">iter</span> <span class="o">=</span> <span class="m">300000</span><span class="p">;</span> iter &lt;<span class="o">=</span> <span class="m">500000</span><span class="p">;</span> <span class="nv">iter</span><span class="o">+=</span><span class="m">2000</span><span class="o">))</span><span class="p">;</span> <span class="k">do</span>
    <span class="c1"># add command with `checkpoint_$iter.pth`</span>
<span class="k">done</span>
</pre></div>
</div>
<p>This script write metric to tensorboard logs in the same pretraining directory,
all VOC07 mAP curves appear together with pretraining loss curves.</p>
</div>
<hr class="docutils" />
<div class="section" id="imagenet-linear-classification">
<h2>ImageNet Linear Classification<a class="headerlink" href="#imagenet-linear-classification" title="Permalink to this headline">¶</a></h2>
<p>We train a linear classifier on 2048-dimensional global average pooled features
extracted from a frozen visual backbone. Evaluate a checkpoint (for example,
iteration 500000) on this task as:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/clf_linear.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --down-config configs/downstream/imagenet_clf.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/imagenet_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">5005</span>  <span class="c1"># 1 epoch of ImageNet</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="instance-segmentation-and-object-detection-on-coco">
<h2>Instance Segmentation (and Object Detection) on COCO<a class="headerlink" href="#instance-segmentation-and-object-detection-on-coco" title="Permalink to this headline">¶</a></h2>
<p>Train a Mask R-CNN with FPN backbone for COCO Instance Segmentation (and Object
Detection, because it also has a box head) by initializing the backbone from
VirTex pretrained weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_detectron2.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --d2-config configs/detectron2/coco_segm_default_init_2x.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">2</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/coco_segm_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">5000</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>This script periodically serializes checkpoints but skips validation
step during training for saving time; to evaluate a serialized checkpoint
and write results to tensorboard, provide it as <code class="docutils literal notranslate"><span class="pre">--checkpoint-path</span></code> and
additional flags <code class="docutils literal notranslate"><span class="pre">--resume</span> <span class="pre">--eval-only</span></code>.</p></li>
<li><p>Note that <code class="docutils literal notranslate"><span class="pre">--d2-config</span></code> here is in Detectron2 format, and not our
package <a class="reference internal" href="../config.html#virtex.config.Config" title="virtex.config.Config"><code class="xref py py-class docutils literal notranslate"><span class="pre">Config</span></code></a>.</p></li>
</ol>
<p>These points are applicable for all tasks described below.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="instance-segmentation-on-lvis">
<h2>Instance Segmentation on LVIS<a class="headerlink" href="#instance-segmentation-on-lvis" title="Permalink to this headline">¶</a></h2>
<p>Train a Mask R-CNN with FPN backbone for LVIS Instance Segmentation by
initializing the backbone from VirTex pretrained weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_detectron2.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --d2-config configs/detectron2/lvis_segm_default_init_2x.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">2</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/lvis_segm_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">5000</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="object-detection-on-pascal-voc-2007-12">
<h2>Object Detection on PASCAL VOC 2007+12<a class="headerlink" href="#object-detection-on-pascal-voc-2007-12" title="Permalink to this headline">¶</a></h2>
<p>Train a Faster R-CNN with C4 backbone for PASCAL VOC 2007+12 Object Detection
by initializing the backbone from VirTex pretrained weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_detectron2.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --d2-config configs/detectron2/voc_det_default_init_24k.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">2</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/voc_det_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">2500</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="inaturalist-2018-fine-grained-classification">
<h2>iNaturalist 2018 Fine-Grained Classification<a class="headerlink" href="#inaturalist-2018-fine-grained-classification" title="Permalink to this headline">¶</a></h2>
<p>Fine-tune the VirTex pretrained visual backbone end-to-end on iNaturalist 2018
dataset:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/clf_linear.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --down-config configs/downstream/inaturalist_clf.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --weight-init virtex <span class="se">\</span>
    --num-gpus-per-machine <span class="m">8</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span> <span class="se">\</span>
    --serialization-dir /tmp/bicaptioning_R_50_L1_H2048/inaturalist_500000 <span class="se">\</span>
    --checkpoint-every <span class="m">1710</span>  <span class="c1"># 1 epoch of iNaturalist</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="image-captioning-on-coco-captions-val2017">
<h2>Image Captioning on COCO Captions val2017<a class="headerlink" href="#image-captioning-on-coco-captions-val2017" title="Permalink to this headline">¶</a></h2>
<p>Evaluate a pretrained VirTex model on image captioning for COCO Captions val2017
split (reporting CIDEr and SPICE metics):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_captioning.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --calc-metrics <span class="se">\</span>
    --num-gpus-per-machine <span class="m">1</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="running-image-captioning-inference-on-arbitrary-images">
<h2>Running Image Captioning Inference on Arbitrary Images<a class="headerlink" href="#running-image-captioning-inference-on-arbitrary-images" title="Permalink to this headline">¶</a></h2>
<p>The above script can be used for generating captions for any images in a directory.
Replace certain commands as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python scripts/eval_captioning.py <span class="se">\</span>
    --config /tmp/bicaptioning_R_50_L1_H2048/pretrain_config.yaml <span class="se">\</span>
    --checkpoint-path /tmp/bicaptioning_R_50_L1_H2048/checkpoint_500000.pth <span class="se">\</span>
    --data-root /path/to/images_dir <span class="se">\</span>
    --output /path/to/save/predictions.json <span class="se">\</span>
    --num-gpus-per-machine <span class="m">1</span> <span class="se">\</span>
    --cpu-workers <span class="m">4</span>
</pre></div>
</div>
<p>This script will save predictions in JSON format. Since our goal is to not
improve image captioning, these models may not generate the best captions.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">virtex</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup_dependencies.html">How to setup this codebase?</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">VirTex Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrain.html">How to train your VirTex model?</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to evaluate on downstream tasks?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pascal-voc-2007-linear-classification">PASCAL VOC 2007 Linear Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#imagenet-linear-classification">ImageNet Linear Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#instance-segmentation-and-object-detection-on-coco">Instance Segmentation (and Object Detection) on COCO</a></li>
<li class="toctree-l2"><a class="reference internal" href="#instance-segmentation-on-lvis">Instance Segmentation on LVIS</a></li>
<li class="toctree-l2"><a class="reference internal" href="#object-detection-on-pascal-voc-2007-12">Object Detection on PASCAL VOC 2007+12</a></li>
<li class="toctree-l2"><a class="reference internal" href="#inaturalist-2018-fine-grained-classification">iNaturalist 2018 Fine-Grained Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#image-captioning-on-coco-captions-val2017">Image Captioning on COCO Captions val2017</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-image-captioning-inference-on-arbitrary-images">Running Image Captioning Inference on Arbitrary Images</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../config.html">virtex.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factories.html">virtex.factories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">virtex.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">virtex.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">virtex.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optim.html">virtex.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">virtex.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">virtex.model_zoo</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="pretrain.html" title="previous chapter">How to train your VirTex model?</a></li>
      <li>Next: <a href="../config.html" title="next chapter">virtex.config</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Karan Desai and Justin Johnson.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.1.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/virtex/usage/downstream.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>