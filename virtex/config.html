
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120523111-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120523111-2');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Inconsolata&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono&display=swap" rel="stylesheet">


    <title>virtex.config &#8212; virtex 0.9 documentation</title>

    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="virtex.factories" href="factories.html" />
    <link rel="prev" title="How to evaluate on downstream tasks?" href="usage/downstream.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="virtex-config">
<h1>virtex.config<a class="headerlink" href="#virtex-config" title="Permalink to this headline">¶</a></h1>
<hr><span class="target" id="module-virtex.config"></span><dl class="py class">
<dt id="virtex.config.Config">
<em class="property">class </em><code class="sig-prename descclassname">virtex.config.</code><code class="sig-name descname">Config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config_file</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">override_list</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Any<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">[]</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/kdexd/virtex/blob/master/virtex/config.py#L6-L242"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#virtex.config.Config" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class provides package-wide configuration management. It is a
nested dict-like structure with nested keys accessible as attributes. It
contains sensible default values, which can be modified by (first) a YAML
file and (second) a list of attributes and values.</p>
<p>An instantiated object is immutable: modifying any attribute is illegal.
You must override required parameter values either through <code class="docutils literal notranslate"><span class="pre">config_file</span></code>
or <code class="docutils literal notranslate"><span class="pre">override_list</span></code> arguments. For adding more parameters at runtime
(based on existing parameters), modify <a class="reference internal" href="#virtex.config.Config.add_derived_params" title="virtex.config.Config.add_derived_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">add_derived_params()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>config_file: str</strong></dt><dd><p>Path to a YAML file containing configuration parameters to override.</p>
</dd>
<dt><strong>config_override: List[Any], optional (default = [])</strong></dt><dd><p>A list of sequential attributes and values of parameters to override.
This happens after overriding from YAML file.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Let a YAML file named “config.yaml” specify these parameters to override:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">OPTIM</span><span class="p">:</span>
  <span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="mi">512</span>
  <span class="n">LR</span><span class="p">:</span> <span class="mf">0.01</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="s2">&quot;config.yaml&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;OPTIM.BATCH_SIZE&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">LR</span>  <span class="c1"># default: 0.001</span>
<span class="go">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">BATCH_SIZE</span>  <span class="c1"># default: 256, file: 512</span>
<span class="go">1024</span>
</pre></div>
</div>
<dl class="py method">
<dt id="virtex.config.Config.add_derived_params">
<code class="sig-name descname">add_derived_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/kdexd/virtex/blob/master/virtex/config.py#L219-L223"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#virtex.config.Config.add_derived_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Add parameters with values derived from existing parameters.</p>
</dd></dl>

<dl class="py method">
<dt id="virtex.config.Config.dump">
<code class="sig-name descname">dump</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">file_path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/kdexd/virtex/blob/master/virtex/config.py#L225-L233"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#virtex.config.Config.dump" title="Permalink to this definition">¶</a></dt>
<dd><p>Save config at the specified file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>file_path: str</strong></dt><dd><p>(YAML) path to save config at.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="config-references">
<h2>Config References<a class="headerlink" href="#config-references" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1"># Random seed for NumPy and PyTorch, important for reproducibility.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># Train with Automatic Mixed Precision (native PyTorch).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">AMP</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1"># Set CUDNN deterministic flag (torch.backends.cudnn.deterministic).</span>
<span class="c1"># Setting this will ensure exact results on every run at the cost of</span>
<span class="c1"># little slowdown. Good for debugging.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">CUDNN_DETERMINISTIC</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># Set CUDNN benchmark flag (torch.backends.cudnn.benchmark). Enables</span>
<span class="c1"># CUDNN to select fastest implementation for operations based on GPU.</span>
<span class="c1"># May change results (in decimals) on different hardware, but faster</span>
<span class="c1"># to train. Turn off while debugging.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">CUDNN_BENCHMARK</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># ---------------------------------------------------------------------</span>
<span class="c1">#   Data paths and parameters related to dataloading.</span>
<span class="c1"># ---------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Path to the dataset root, which structure as per README. Path is</span>
<span class="c1"># assumed to be relative to project root.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">ROOT</span> <span class="o">=</span> <span class="s2">&quot;datasets/coco&quot;</span>
<span class="c1"># Path to .model file generated by ``sentencepiece``.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TOKENIZER_MODEL</span> <span class="o">=</span> <span class="s2">&quot;datasets/vocab/coco_10k.model&quot;</span>

<span class="c1"># Handy config params for vocab size and indices of special tokens.</span>
<span class="c1"># While these can be picked up from the tokenizer, having these in</span>
<span class="c1"># the config makes it easy to create a model without instantiating too</span>
<span class="c1"># many tokenizer instances (especially when not needed, e.g. model zoo).</span>
<span class="c1"># These must match according to what&#39;s present in ``TOKENIZER_VOCAB``</span>
<span class="c1"># and ``TOKENIZER_MODEL`` above.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c1"># Index of out-of-vocabulary (and padding) token.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">UNK_INDEX</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># Index of the start-of-sentence [SOS] token.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">SOS_INDEX</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Index of the end-of-sentence [EOS] token.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">EOS_INDEX</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Index of the word masking token. While not used for captioning, having</span>
<span class="c1"># this extra token makes it possible to train an MLM model without</span>
<span class="c1"># re-creating a new vocab mapping.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASK_INDEX</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># Size of the image (square) to crop from original input image.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">IMAGE_CROP_SIZE</span> <span class="o">=</span> <span class="mi">224</span>
<span class="c1"># Maximum length of input caption (number of tokens).</span>
<span class="c1"># Longer captions will be truncated up to this length.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MAX_CAPTION_LENGTH</span> <span class="o">=</span> <span class="mi">30</span>

<span class="c1"># COCO Captions has five captions per image. If ``True``, training will</span>
<span class="c1"># use one random caption per image (data efficiency ablations).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">USE_SINGLE_CAPTION</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># Percentage of dataset to use for training (data efficiency ablations).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">USE_PERCENTAGE</span> <span class="o">=</span> <span class="mf">100.0</span>

<span class="c1"># List of image transforms (pre-processing and data augmentation) to be</span>
<span class="c1"># applied sequentially (always or randomly) during training and</span>
<span class="c1"># validation. Refer ``virtex/facetories.py`` for all possible transforms.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">IMAGE_TRANSFORM_TRAIN</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;random_resized_crop&quot;</span><span class="p">,</span>
    <span class="s2">&quot;horizontal_flip&quot;</span><span class="p">,</span>
    <span class="s2">&quot;color_jitter&quot;</span><span class="p">,</span>
    <span class="s2">&quot;normalize&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">IMAGE_TRANSFORM_VAL</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;smallest_resize&quot;</span><span class="p">,</span>
    <span class="s2">&quot;center_crop&quot;</span><span class="p">,</span>
    <span class="s2">&quot;normalize&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Hyper-parameters for masked LM pretraining task. These are only used</span>
<span class="c1"># when ``MODEL.NAME`` is &quot;masked_lm&quot;.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="c1"># Fraction of tokens to choose for masking, this must be less than 1.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span><span class="o">.</span><span class="n">MASK_PROPORTION</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="c1"># Probability to replace chosen tokens with [MASK] token.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span><span class="o">.</span><span class="n">MASK_PROBABILITY</span> <span class="o">=</span> <span class="mf">0.85</span>
<span class="c1"># Probability to replace chosen tokens with a random token.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span><span class="o">.</span><span class="n">REPLACE_PROBABILITY</span> <span class="o">=</span> <span class="mf">0.10</span>

<span class="c1"># ---------------------------------------------------------------------</span>
<span class="c1">#   Model architecture: visual backbone and textual head.</span>
<span class="c1"># ---------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Name of model, based on pretraining task.</span>
<span class="c1"># Possible choices: {&quot;token_classification&quot;, &quot;multilabel_classification&quot;,</span>
<span class="c1"># &quot;captioning&quot;, &quot;bicaptioning&quot;, &quot;masked_lm&quot;, &quot;virtex&quot;}</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;virtex&quot;</span>

<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="c1"># Name of visual backbone. Possible choices: {&quot;blind&quot;, &quot;torchvision&quot;}</span>
<span class="c1"># Models from torchvision can be specified as shown below.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;torchvision::resnet50&quot;</span>
<span class="c1"># Number of channels in pooled spatial features of visual backbone.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">FEATURE_SIZE</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="c1"># Whether to load ImageNet pretrained weights into visual backbone.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">PRETRAINED</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># Whether to keep visual backbone frozen and train only textual head.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">FROZEN</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">TEXTUAL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="c1"># Name of textual head. Set to &quot;none&quot; for MODEL.NAME = &quot;*_classification&quot;.</span>
<span class="c1"># Possible choices: {&quot;transformer_postnorm&quot;, &quot;transformer_prenorm&quot;}.</span>
<span class="c1"># Architectural hyper-parameters are specified as shown above.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">TEXTUAL</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;transformer_postnorm::L1_H2048_A32_F8192&quot;</span>
<span class="c1"># L = Number of layers in the transformer.</span>
<span class="c1"># H = Hidden size of the transformer (embeddings, attention features).</span>
<span class="c1"># A = Number of attention heads in the transformer.</span>
<span class="c1"># F = Size of feedforward layers in the transformer.</span>
<span class="c1"># Typically, we have (A = H / 64) and (F = 4 * H).</span>

<span class="c1"># Dropout probability for embedding, hidden features in textual head.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">TEXTUAL</span><span class="o">.</span><span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># ---------------------------------------------------------------------</span>
<span class="c1">#   Optimization hyper-parameters, default values are for pretraining</span>
<span class="c1">#   our best model on bicaptioning task (COCO Captions).</span>
<span class="c1"># ---------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Name of optimizer to use. Supported values: {&quot;sgd&quot;, &quot;adamw&quot;}.</span>
<span class="c1"># AdamW uses default (beta1, beta2) values from PyTorch.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">OPTIMIZER_NAME</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span>
<span class="c1"># Momentum co-efficient for SGD. Ignored for AdamW.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">SGD_MOMENTUM</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="c1"># Weight decay co-efficient for the optimizer.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="c1"># Regex pattern of params for which there will be no weight decay.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">NO_DECAY</span> <span class="o">=</span> <span class="s2">&quot;.*textual.(embedding|transformer).*(norm.*|bias)&quot;</span>
<span class="c1"># Max gradient norm for clipping to avoid exploding gradients.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">CLIP_GRAD_NORM</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Wrap our optimizer with Lookahead (https://arxiv.org/abs/1907.08610).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">USE_LOOKAHEAD</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LOOKAHEAD_ALPHA</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LOOKAHEAD_STEPS</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># We set different learning rates for CNN (visual backbone) and rest of</span>
<span class="c1"># the model. CNN LR is typically much higher for training from scratch.</span>
<span class="c1"># Both LRs undergo same warmup-decay schedules.</span>

<span class="c1"># Total batch size (will be distributed evenly across GPUs).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Max learning rate for CNN (visual backbone).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">CNN_LR</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="c1"># Max learning rate for rest of the model.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Number of iterations to train for, batches are randomly sampled.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">NUM_ITERATIONS</span> <span class="o">=</span> <span class="mi">500000</span>

<span class="c1"># Number of steps at the start of training for linear LR warmup.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c1"># Learning rate annealing schedule for decay after warmup.</span>
<span class="c1"># Possible choices: {&quot;none&quot;, &quot;linear&quot;, &quot;cosine&quot;, &quot;multistep&quot;}.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_DECAY_NAME</span> <span class="o">=</span> <span class="s2">&quot;cosine&quot;</span>
<span class="c1"># Steps to decay LR for &quot;multistep&quot; schedule.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_STEPS</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># Factor to multiply with LR for &quot;multistep&quot; schedule.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_GAMMA</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</td></tr></table></div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">virtex</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage/setup_dependencies.html">How to setup this codebase?</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/model_zoo.html">VirTex Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/pretrain.html">How to train your VirTex model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/downstream.html">How to evaluate on downstream tasks?</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">virtex.config</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#config-references">Config References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="factories.html">virtex.factories</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">virtex.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">virtex.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">virtex.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">virtex.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">virtex.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">virtex.model_zoo</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="usage/downstream.html" title="previous chapter">How to evaluate on downstream tasks?</a></li>
      <li>Next: <a href="factories.html" title="next chapter">virtex.factories</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Karan Desai and Justin Johnson.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.1.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/virtex/config.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>